---
title: "Supported Providers"
description: "Connect to different AI providers like OpenAI, Anthropic, Gemini, and more while maintaining a consistent API across your application."
---

LLM Drivers provide a standardized interface for interacting with different language model providers. Switch between providers without changing your application code.

## Available Drivers

<CardGroup cols={2}>
  <Card title="OpenAI" icon="robot">
    Default driver for OpenAI API. Works with GPT-4, GPT-4o, and other OpenAI models.
  </Card>
  <Card title="Anthropic (Claude)" icon="message">
    Native support for Claude models via the Anthropic API.
  </Card>
  <Card title="Google Gemini" icon="google">
    Native Gemini driver for Google's AI models.
  </Card>
  <Card title="Groq" icon="bolt">
    Ultra-fast inference with Groq's LPU platform.
  </Card>
  <Card title="Ollama" icon="server">
    Run local LLMs with Ollama integration.
  </Card>
  <Card title="OpenRouter" icon="shuffle">
    Access multiple providers through OpenRouter's unified API.
  </Card>
</CardGroup>

All drivers are pre-configured in `config/laragent.php`. Add your API key and you're ready to go.

---

## Quick Setup

### OpenAI (Default)

```env .env
OPENAI_API_KEY=your-api-key
```

```php App/AiAgents/MyAgent.php
class MyAgent extends Agent
{
    protected $provider = 'default'; // Uses OpenAI
    protected $model = 'gpt-4o-mini';
}
```

### Anthropic (Claude)

```env .env
ANTHROPIC_API_KEY=your-api-key
```

```php App/AiAgents/MyAgent.php
class MyAgent extends Agent
{
    protected $provider = 'claude';
    protected $model = 'claude-sonnet-4-20250514';
}
```

<Check>
Claude supports structured output (response schemas) for type-safe JSON responses from v1.1.0
</Check>

### Google Gemini

```env .env
GEMINI_API_KEY=your-api-key
```

```php App/AiAgents/MyAgent.php
class MyAgent extends Agent
{
    protected $provider = 'gemini';
    protected $model = 'gemini-2.5-pro-preview-03-25';
}
```

### Groq

```env .env
GROQ_API_KEY=your-api-key
```

```php App/AiAgents/MyAgent.php
class MyAgent extends Agent
{
    protected $provider = 'groq';
    protected $model = 'llama-3.3-70b-versatile';
}
```

### Ollama (Local)

```php App/AiAgents/MyAgent.php
class MyAgent extends Agent
{
    protected $provider = 'ollama';
    protected $model = 'llama2'; // Any model installed in Ollama
}
```

### OpenRouter

```env .env
OPENROUTER_API_KEY=your-api-key
```

```php App/AiAgents/MyAgent.php
class MyAgent extends Agent
{
    protected $provider = 'openrouter';
    protected $model = 'anthropic/claude-3-opus';
}
```

---

## Configuration

### Global Configuration

Configure providers in `config/laragent.php`:

```php config/laragent.php
'providers' => [
    'default' => [
        'label' => 'openai',
        'api_key' => env('OPENAI_API_KEY'),
        'driver' => \LarAgent\Drivers\OpenAi\OpenAiDriver::class,
        'default_temperature' => 1,
        'default_max_completion_tokens' => 2048,
    ],
    
    'claude' => [
        'label' => 'anthropic',
        'api_key' => env('ANTHROPIC_API_KEY'),
        'driver' => \LarAgent\Drivers\Anthropic\ClaudeDriver::class,
    ],
],
```

### Per-Agent Configuration

Override the driver directly in your agent:

```php
use LarAgent\Drivers\OpenAi\OpenAiCompatible;

class MyAgent extends Agent
{
    protected $driver = OpenAiCompatible::class;
    protected $provider = 'custom-provider';
}
```

<Info>
Agent-level driver configuration overrides the global provider settings.
</Info>

---

## Multi-Provider Fallback

Automatically switch between AI providers when one fails, ensuring your agents stay operational even when a provider is down or rate-limited.

### Per-Agent Configuration

Set multiple providers directly in your agent using an array:

```php App/AiAgents/MyAgent.php
class MyAgent extends Agent
{
    // First is primary, others are fallbacks in order
    protected $provider = ['openai', 'gemini', 'claude'];
    
    public function instructions()
    {
        return 'You are a helpful assistant.';
    }
}
```

### With Per-Provider Overrides

Override specific settings for each provider in the fallback chain:

```php App/AiAgents/MyAgent.php
class MyAgent extends Agent
{
    protected $provider = [
        'openai',
        'gemini' => ['model' => 'gemini-2.0-flash'],
        'claude',
    ];
    
    public function instructions()
    {
        return 'You are a helpful assistant.';
    }
}
```

### Global Configuration

Set default fallback providers for all agents in `config/laragent.php`:

```php config/laragent.php
return [
    'providers' => [
        'default' => [
            'label' => 'openai',
            'model' => 'gpt-4o-mini',
            'api_key' => env('OPENAI_API_KEY'),
            'driver' => \LarAgent\Drivers\OpenAi\OpenAiDriver::class,
        ],
        
        'gemini' => [
            'label' => 'gemini',
            'model' => 'gemini-2.0-flash',
            'api_key' => env('GEMINI_API_KEY'),
            'driver' => \LarAgent\Drivers\Gemini\GeminiDriver::class,
        ],
        
        'claude' => [
            'label' => 'anthropic',
            'api_key' => env('ANTHROPIC_API_KEY'),
            'driver' => \LarAgent\Drivers\Anthropic\ClaudeDriver::class,
        ],
    ],
    
    // Global fallback chain for all agents
    'default_providers' => [
        'openai',
        'gemini' => ['model' => 'gemini-2.0-flash'],
        'claude',
    ],
];
```

<Tip>
Agent-level `$provider` array takes precedence over `default_providers` config.
</Tip>

### Debugging Fallback

Use these methods to inspect the provider sequence and active provider:

```php
$agent = MyAgent::make();

// Get the configured provider sequence
$sequence = $agent->getProviderSequence();
// ['openai', 'gemini', 'claude']

// After a response, check which provider was used
$response = $agent->respond('Hello!');
$activeProvider = $agent->getActiveProviderName();
// 'openai' (or 'gemini' if openai failed)
```

<Warning>
The `fallback_provider` config option is deprecated. Use `default_providers` or array-based `$provider` instead.
</Warning>

---

## Driver Reference

| Driver | Class | Provider Key |
|--------|-------|--------------|
| OpenAI | `LarAgent\Drivers\OpenAi\OpenAiDriver` | `default` |
| OpenAI Compatible | `LarAgent\Drivers\OpenAi\OpenAiCompatible` | — |
| Anthropic | `LarAgent\Drivers\Anthropic\ClaudeDriver` | `claude` |
| Gemini | `LarAgent\Drivers\Gemini\GeminiDriver` | `gemini` |
| Groq | `LarAgent\Drivers\Groq\GroqDriver` | `groq` |
| Ollama | `LarAgent\Drivers\OpenAi\OllamaDriver` | `ollama` |
| OpenRouter | `LarAgent\Drivers\OpenAi\OpenAiCompatible` | `openrouter` |

<Tip>
The `OpenAiCompatible` driver works with any API that follows the OpenAI format, making it easy to integrate with custom or self-hosted solutions.
</Tip>

---

## Best Practices

<Check>
Store API keys in environment variables — never hardcode them.
</Check>

<Check>
Configure multi-provider fallback for production reliability.
</Check>

<Warning>
Not all providers support the same features. Check provider documentation for streaming, tool calling, and structured output support.
</Warning>

## Next Steps

<CardGroup cols={2}>
  <Card title="Create & Configure" icon="gear" href="/v1/agents/creation">
    Configure agents with different providers.
  </Card>
  <Card title="Streaming" icon="wave-pulse" href="/v1/responses/streaming">
    Enable real-time streaming responses.
  </Card>
  <Card title="Structured Output" icon="brackets-curly" href="/v1/responses/structured-output">
    Get typed, validated responses from your agents.
  </Card>
  <Card title="Context Overview" icon="database" href="/v1/context/overview">
    Manage conversation history and agent state.
  </Card>
</CardGroup>
