---
title: "Supported Providers"
description: "Connect to different AI providers like OpenAI, Anthropic, Gemini, and more while maintaining a consistent API across your application."
---

LLM Drivers provide a standardized interface for interacting with different language model providers. Switch between providers without changing your application code.

## Available Drivers

<CardGroup cols={2}>
  <Card title="OpenAI" icon="robot">
    Default driver for OpenAI API. Works with GPT-4, GPT-4o, and other OpenAI models.
  </Card>
  <Card title="Anthropic (Claude)" icon="message">
    Native support for Claude models via the Anthropic API.
  </Card>
  <Card title="Google Gemini" icon="google">
    Native Gemini driver for Google's AI models.
  </Card>
  <Card title="Groq" icon="bolt">
    Ultra-fast inference with Groq's LPU platform.
  </Card>
  <Card title="Ollama" icon="server">
    Run local LLMs with Ollama integration.
  </Card>
  <Card title="OpenRouter" icon="shuffle">
    Access multiple providers through OpenRouter's unified API.
  </Card>
</CardGroup>

All drivers are pre-configured in `config/laragent.php`. Add your API key and you're ready to go.

---

## Quick Setup

### OpenAI (Default)

```env .env
OPENAI_API_KEY=your-api-key
```

```php App/AiAgents/MyAgent.php
class MyAgent extends Agent
{
    protected $provider = 'default'; // Uses OpenAI
    protected $model = 'gpt-4o-mini';
}
```

### Anthropic (Claude)

```env .env
ANTHROPIC_API_KEY=your-api-key
```

```php App/AiAgents/MyAgent.php
class MyAgent extends Agent
{
    protected $provider = 'claude';
    protected $model = 'claude-sonnet-4-20250514';
}
```

### Google Gemini

```env .env
GEMINI_API_KEY=your-api-key
```

```php App/AiAgents/MyAgent.php
class MyAgent extends Agent
{
    protected $provider = 'gemini';
    protected $model = 'gemini-2.5-pro-preview-03-25';
}
```

### Groq

```env .env
GROQ_API_KEY=your-api-key
```

```php App/AiAgents/MyAgent.php
class MyAgent extends Agent
{
    protected $provider = 'groq';
    protected $model = 'llama-3.3-70b-versatile';
}
```

### Ollama (Local)

```php App/AiAgents/MyAgent.php
class MyAgent extends Agent
{
    protected $provider = 'ollama';
    protected $model = 'llama2'; // Any model installed in Ollama
}
```

### OpenRouter

```env .env
OPENROUTER_API_KEY=your-api-key
```

```php App/AiAgents/MyAgent.php
class MyAgent extends Agent
{
    protected $provider = 'openrouter';
    protected $model = 'anthropic/claude-3-opus';
}
```

---

## Configuration

### Global Configuration

Configure providers in `config/laragent.php`:

```php config/laragent.php
'providers' => [
    'default' => [
        'label' => 'openai',
        'api_key' => env('OPENAI_API_KEY'),
        'driver' => \LarAgent\Drivers\OpenAi\OpenAiDriver::class,
        'default_temperature' => 1,
        'default_max_completion_tokens' => 2048,
    ],
    
    'claude' => [
        'label' => 'anthropic',
        'api_key' => env('ANTHROPIC_API_KEY'),
        'driver' => \LarAgent\Drivers\Anthropic\ClaudeDriver::class,
    ],
],
```

### Per-Agent Configuration

Override the driver directly in your agent:

```php
use LarAgent\Drivers\OpenAi\OpenAiCompatible;

class MyAgent extends Agent
{
    protected $driver = OpenAiCompatible::class;
    protected $provider = 'custom-provider';
}
```

<Info>
Agent-level driver configuration overrides the global provider settings.
</Info>

---

## Fallback Provider

Configure a fallback provider that activates when the primary provider fails:

```php config/laragent.php
return [
    'providers' => [
        'default' => [
            'label' => 'openai',
            'model' => 'gpt-4o-mini',
            'api_key' => env('OPENAI_API_KEY'),
            'driver' => \LarAgent\Drivers\OpenAi\OpenAiDriver::class,
        ],
        
        'gemini' => [
            'label' => 'gemini',
            'model' => 'gemini-2.0-flash',
            'api_key' => env('GEMINI_API_KEY'),
            'driver' => \LarAgent\Drivers\Gemini\GeminiDriver::class,
        ],
    ],
    
    // Use Gemini as fallback when OpenAI fails
    'fallback_provider' => 'gemini',
];
```

<Warning>
Always set a `model` in the fallback provider configuration to ensure it works correctly.
</Warning>

---

## Driver Reference

| Driver | Class | Provider Key |
|--------|-------|--------------|
| OpenAI | `LarAgent\Drivers\OpenAi\OpenAiDriver` | `default` |
| OpenAI Compatible | `LarAgent\Drivers\OpenAi\OpenAiCompatible` | — |
| Anthropic | `LarAgent\Drivers\Anthropic\ClaudeDriver` | `claude` |
| Gemini | `LarAgent\Drivers\Gemini\GeminiDriver` | `gemini` |
| Groq | `LarAgent\Drivers\Groq\GroqDriver` | `groq` |
| Ollama | `LarAgent\Drivers\OpenAi\OllamaDriver` | `ollama` |
| OpenRouter | `LarAgent\Drivers\OpenAi\OpenAiCompatible` | `openrouter` |

<Tip>
The `OpenAiCompatible` driver works with any API that follows the OpenAI format, making it easy to integrate with custom or self-hosted solutions.
</Tip>

---

## Best Practices

<Check>
Store API keys in environment variables — never hardcode them.
</Check>

<Check>
Configure a fallback provider for production reliability.
</Check>

<Warning>
Not all providers support the same features. Check provider documentation for streaming, tool calling, and structured output support.
</Warning>

## Next Steps

<CardGroup cols={2}>
  <Card title="Create & Configure" icon="gear" href="/v1/agents/creation">
    Configure agents with different providers.
  </Card>
  <Card title="Streaming" icon="wave-pulse" href="/v1/responses/streaming">
    Enable real-time streaming responses.
  </Card>
  <Card title="Structured Output" icon="brackets-curly" href="/v1/responses/structured-output">
    Get typed, validated responses from your agents.
  </Card>
  <Card title="Context Overview" icon="database" href="/v1/context/overview">
    Manage conversation history and agent state.
  </Card>
</CardGroup>
